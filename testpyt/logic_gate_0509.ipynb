{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=np.array([[0,0],[0,1],[1,0],[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_gate(x):\n",
    "    w1=0.5\n",
    "    w2=0.5\n",
    "    b=-0.8\n",
    "\n",
    "    result=x[0]*w1+x[1]*w2+b\n",
    "    if result <=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for x in input_data:\n",
    "    result.append(AND_gate(x))\n",
    "print(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND_gate(x):\n",
    "    w1=-0.5\n",
    "    w2=-0.5\n",
    "    b=0.7\n",
    "    result=x[0]*w1 + x[1]*w2 +b\n",
    "    if result <=0:\n",
    "        return 0\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for x in input_data:\n",
    "    result.append(NAND_gate(x))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_gate(x):\n",
    "    w1= 0.6\n",
    "    w2= 0.6\n",
    "    b=-0.5\n",
    "    result=x[0]*w1 + x[1]*w2 +b\n",
    "    if result <=0:\n",
    "        return 0\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for x in input_data:\n",
    "    result.append(OR_gate(x))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "s1=[] # NAND 출력결과\n",
    "s2=[] # OR 출력결과\n",
    "\n",
    "new_input=[] # AND 입력\n",
    "final_output=[] # 최종 출력값\n",
    "\n",
    "for i in range(len(input_data)):\n",
    "    s1=NAND_gate(input_data[i])\n",
    "    s2=OR_gate(input_data[i])\n",
    "    new_input.append(s1)\n",
    "    new_input.append(s2)\n",
    "\n",
    "    result=AND_gate(new_input)\n",
    "    final_output.append(result)\n",
    "    new_input=[]\n",
    "print(final_output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_data=np.array([[0,0], [0,1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.from_numpy(input_data).float()\n",
    "Y=torch.FloatTensor([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear= nn.Linear(2,1, bias=True)\n",
    "sigmoid=nn.Sigmoid()\n",
    "model=nn.Sequential(linear, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 0.713618994\n",
      "step: 100, cost: 0.693150222\n",
      "step: 200, cost: 0.693147123\n",
      "step: 300, cost: 0.693147182\n",
      "step: 400, cost: 0.693147182\n",
      "step: 500, cost: 0.693147182\n",
      "step: 600, cost: 0.693147182\n",
      "step: 700, cost: 0.693147182\n",
      "step: 800, cost: 0.693147182\n",
      "step: 900, cost: 0.693147182\n",
      "step: 1000, cost: 0.693147182\n",
      "step: 1100, cost: 0.693147182\n",
      "step: 1200, cost: 0.693147182\n",
      "step: 1300, cost: 0.693147182\n",
      "step: 1400, cost: 0.693147182\n",
      "step: 1500, cost: 0.693147182\n",
      "step: 1600, cost: 0.693147182\n",
      "step: 1700, cost: 0.693147182\n",
      "step: 1800, cost: 0.693147182\n",
      "step: 1900, cost: 0.693147182\n",
      "step: 2000, cost: 0.693147182\n",
      "step: 2100, cost: 0.693147182\n",
      "step: 2200, cost: 0.693147182\n",
      "step: 2300, cost: 0.693147182\n",
      "step: 2400, cost: 0.693147182\n",
      "step: 2500, cost: 0.693147182\n",
      "step: 2600, cost: 0.693147182\n",
      "step: 2700, cost: 0.693147182\n",
      "step: 2800, cost: 0.693147182\n",
      "step: 2900, cost: 0.693147182\n",
      "step: 3000, cost: 0.693147182\n",
      "step: 3100, cost: 0.693147182\n",
      "step: 3200, cost: 0.693147182\n",
      "step: 3300, cost: 0.693147182\n",
      "step: 3400, cost: 0.693147182\n",
      "step: 3500, cost: 0.693147182\n",
      "step: 3600, cost: 0.693147182\n",
      "step: 3700, cost: 0.693147182\n",
      "step: 3800, cost: 0.693147182\n",
      "step: 3900, cost: 0.693147182\n",
      "step: 4000, cost: 0.693147182\n",
      "step: 4100, cost: 0.693147182\n",
      "step: 4200, cost: 0.693147182\n",
      "step: 4300, cost: 0.693147182\n",
      "step: 4400, cost: 0.693147182\n",
      "step: 4500, cost: 0.693147182\n",
      "step: 4600, cost: 0.693147182\n",
      "step: 4700, cost: 0.693147182\n",
      "step: 4800, cost: 0.693147182\n",
      "step: 4900, cost: 0.693147182\n",
      "step: 5000, cost: 0.693147182\n",
      "step: 5100, cost: 0.693147182\n",
      "step: 5200, cost: 0.693147182\n",
      "step: 5300, cost: 0.693147182\n",
      "step: 5400, cost: 0.693147182\n",
      "step: 5500, cost: 0.693147182\n",
      "step: 5600, cost: 0.693147182\n",
      "step: 5700, cost: 0.693147182\n",
      "step: 5800, cost: 0.693147182\n",
      "step: 5900, cost: 0.693147182\n",
      "step: 6000, cost: 0.693147182\n",
      "step: 6100, cost: 0.693147182\n",
      "step: 6200, cost: 0.693147182\n",
      "step: 6300, cost: 0.693147182\n",
      "step: 6400, cost: 0.693147182\n",
      "step: 6500, cost: 0.693147182\n",
      "step: 6600, cost: 0.693147182\n",
      "step: 6700, cost: 0.693147182\n",
      "step: 6800, cost: 0.693147182\n",
      "step: 6900, cost: 0.693147182\n",
      "step: 7000, cost: 0.693147182\n",
      "step: 7100, cost: 0.693147182\n",
      "step: 7200, cost: 0.693147182\n",
      "step: 7300, cost: 0.693147182\n",
      "step: 7400, cost: 0.693147182\n",
      "step: 7500, cost: 0.693147182\n",
      "step: 7600, cost: 0.693147182\n",
      "step: 7700, cost: 0.693147182\n",
      "step: 7800, cost: 0.693147182\n",
      "step: 7900, cost: 0.693147182\n",
      "step: 8000, cost: 0.693147182\n",
      "step: 8100, cost: 0.693147182\n",
      "step: 8200, cost: 0.693147182\n",
      "step: 8300, cost: 0.693147182\n",
      "step: 8400, cost: 0.693147182\n",
      "step: 8500, cost: 0.693147182\n",
      "step: 8600, cost: 0.693147182\n",
      "step: 8700, cost: 0.693147182\n",
      "step: 8800, cost: 0.693147182\n",
      "step: 8900, cost: 0.693147182\n",
      "step: 9000, cost: 0.693147182\n",
      "step: 9100, cost: 0.693147182\n",
      "step: 9200, cost: 0.693147182\n",
      "step: 9300, cost: 0.693147182\n",
      "step: 9400, cost: 0.693147182\n",
      "step: 9500, cost: 0.693147182\n",
      "step: 9600, cost: 0.693147182\n",
      "step: 9700, cost: 0.693147182\n",
      "step: 9800, cost: 0.693147182\n",
      "step: 9900, cost: 0.693147182\n",
      "step: 10000, cost: 0.693147182\n"
     ]
    }
   ],
   "source": [
    "crit=torch.nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat=model(X)\n",
    "    cost=crit(y_hat, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(\"step: %d, cost: %.9f\"%(step, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat=model(X)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(\n",
    "    nn.Linear(2, 10, bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 10, bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 10, bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1, bias=True),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 0.709568381\n",
      "step: 100, cost: 0.693175495\n",
      "step: 200, cost: 0.693170547\n",
      "step: 300, cost: 0.693165898\n",
      "step: 400, cost: 0.693161488\n",
      "step: 500, cost: 0.693157136\n",
      "step: 600, cost: 0.693152905\n",
      "step: 700, cost: 0.693148792\n",
      "step: 800, cost: 0.693144679\n",
      "step: 900, cost: 0.693140507\n",
      "step: 1000, cost: 0.693136156\n",
      "step: 1100, cost: 0.693131685\n",
      "step: 1200, cost: 0.693127096\n",
      "step: 1300, cost: 0.693122149\n",
      "step: 1400, cost: 0.693116903\n",
      "step: 1500, cost: 0.693111181\n",
      "step: 1600, cost: 0.693104982\n",
      "step: 1700, cost: 0.693098128\n",
      "step: 1800, cost: 0.693090498\n",
      "step: 1900, cost: 0.693081915\n",
      "step: 2000, cost: 0.693072140\n",
      "step: 2100, cost: 0.693060935\n",
      "step: 2200, cost: 0.693047881\n",
      "step: 2300, cost: 0.693032563\n",
      "step: 2400, cost: 0.693014145\n",
      "step: 2500, cost: 0.692992032\n",
      "step: 2600, cost: 0.692964792\n",
      "step: 2700, cost: 0.692930758\n",
      "step: 2800, cost: 0.692887306\n",
      "step: 2900, cost: 0.692830324\n",
      "step: 3000, cost: 0.692753315\n",
      "step: 3100, cost: 0.692645609\n",
      "step: 3200, cost: 0.692487597\n",
      "step: 3300, cost: 0.692241549\n",
      "step: 3400, cost: 0.691825569\n",
      "step: 3500, cost: 0.691034973\n",
      "step: 3600, cost: 0.689231634\n",
      "step: 3700, cost: 0.683562994\n",
      "step: 3800, cost: 0.648846984\n",
      "step: 3900, cost: 0.440325648\n",
      "step: 4000, cost: 0.016759589\n",
      "step: 4100, cost: 0.006646711\n",
      "step: 4200, cost: 0.003964588\n",
      "step: 4300, cost: 0.002776451\n",
      "step: 4400, cost: 0.002117401\n",
      "step: 4500, cost: 0.001702190\n",
      "step: 4600, cost: 0.001418142\n",
      "step: 4700, cost: 0.001212412\n",
      "step: 4800, cost: 0.001056897\n",
      "step: 4900, cost: 0.000935490\n",
      "step: 5000, cost: 0.000838169\n",
      "step: 5100, cost: 0.000758561\n",
      "step: 5200, cost: 0.000692286\n",
      "step: 5300, cost: 0.000636277\n",
      "step: 5400, cost: 0.000588335\n",
      "step: 5500, cost: 0.000546887\n",
      "step: 5600, cost: 0.000510738\n",
      "step: 5700, cost: 0.000478917\n",
      "step: 5800, cost: 0.000450700\n",
      "step: 5900, cost: 0.000425474\n",
      "step: 6000, cost: 0.000402882\n",
      "step: 6100, cost: 0.000382505\n",
      "step: 6200, cost: 0.000363982\n",
      "step: 6300, cost: 0.000347122\n",
      "step: 6400, cost: 0.000331733\n",
      "step: 6500, cost: 0.000317576\n",
      "step: 6600, cost: 0.000304565\n",
      "step: 6700, cost: 0.000292564\n",
      "step: 6800, cost: 0.000281411\n",
      "step: 6900, cost: 0.000271071\n",
      "step: 7000, cost: 0.000261447\n",
      "step: 7100, cost: 0.000252443\n",
      "step: 7200, cost: 0.000244000\n",
      "step: 7300, cost: 0.000236119\n",
      "step: 7400, cost: 0.000228689\n",
      "step: 7500, cost: 0.000221747\n",
      "step: 7600, cost: 0.000215156\n",
      "step: 7700, cost: 0.000208958\n",
      "step: 7800, cost: 0.000203079\n",
      "step: 7900, cost: 0.000197506\n",
      "step: 8000, cost: 0.000192257\n",
      "step: 8100, cost: 0.000187260\n",
      "step: 8200, cost: 0.000182507\n",
      "step: 8300, cost: 0.000177989\n",
      "step: 8400, cost: 0.000173653\n",
      "step: 8500, cost: 0.000169569\n",
      "step: 8600, cost: 0.000165621\n",
      "step: 8700, cost: 0.000161879\n",
      "step: 8800, cost: 0.000158248\n",
      "step: 8900, cost: 0.000154813\n",
      "step: 9000, cost: 0.000151538\n",
      "step: 9100, cost: 0.000148361\n",
      "step: 9200, cost: 0.000145307\n",
      "step: 9300, cost: 0.000142402\n",
      "step: 9400, cost: 0.000139583\n",
      "step: 9500, cost: 0.000136848\n",
      "step: 9600, cost: 0.000134252\n",
      "step: 9700, cost: 0.000131734\n",
      "step: 9800, cost: 0.000129350\n",
      "step: 9900, cost: 0.000126980\n",
      "step: 10000, cost: 0.000124739\n"
     ]
    }
   ],
   "source": [
    "crit=torch.nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat=model(X)\n",
    "    cost=crit(y_hat, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(\"step: %d, cost: %.9f\"%(step, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 결과: tensor([[8.8006e-05],\n",
      "        [9.9988e-01],\n",
      "        [9.9988e-01],\n",
      "        [1.6399e-04]])\n",
      "모델의 예측값: tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "정확도(Accuracy): tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_hat=model(X)\n",
    "    predicted=(y_hat>0.5).float()\n",
    "    accuracy=(predicted==Y).float().mean()\n",
    "    print(\"모델 학습 결과:\", y_hat)\n",
    "    print(\"모델의 예측값:\",predicted )\n",
    "    print(\"정확도(Accuracy):\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
