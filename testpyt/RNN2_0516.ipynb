{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'a', 'g', 'h', 'm', 'n', 'o', 'p', 'r', 't', 'y'] 11\n"
     ]
    }
   ],
   "source": [
    "input_str='python progra'\n",
    "label_str='ython program'\n",
    "char_vocab=sorted(list(set(input_str+label_str)))\n",
    "vocab_size=len(char_vocab)\n",
    "print(char_vocab, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=vocab_size\n",
    "hidden_size=11\n",
    "output_size=11\n",
    "learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'g': 2, 'h': 3, 'm': 4, 'n': 5, 'o': 6, 'p': 7, 'r': 8, 't': 9, 'y': 10}\n"
     ]
    }
   ],
   "source": [
    "char_to_index=dict((c,i) for i, c in enumerate (char_vocab))\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: 'a', 2: 'g', 3: 'h', 4: 'm', 5: 'n', 6: 'o', 7: 'p', 8: 'r', 9: 't', 10: 'y'}\n"
     ]
    }
   ],
   "source": [
    "index_to_char={}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value]=key\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1]\n",
      "[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "x_data=[char_to_index[c] for c in input_str]\n",
    "y_data=[char_to_index[c] for c in label_str]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1]] [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]]\n"
     ]
    }
   ],
   "source": [
    "x_data=[x_data] # 차원을 하나 올린다\n",
    "y_data=[y_data]\n",
    "print(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot=[np.eye(vocab_size)[x] for x in x_data]\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 11]) tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
      "torch.Size([1, 13]) tensor([[10,  9,  3,  6,  5,  0,  7,  8,  6,  2,  8,  1,  4]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_1832\\1851259994.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  X=torch.FloatTensor(x_one_hot)\n"
     ]
    }
   ],
   "source": [
    "X=torch.FloatTensor(x_one_hot)\n",
    "Y=torch.LongTensor(y_data)\n",
    "print(X.shape, X)\n",
    "print(Y.shape, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn=nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status=self.rnn(x)\n",
    "        x=self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 11]) tensor([[[-0.0934, -0.0555,  0.0891,  0.1597,  0.1576,  0.2273,  0.1699,\n",
      "          -0.1757,  0.2456,  0.1233,  0.2199],\n",
      "         [ 0.2021, -0.0877,  0.1590,  0.1278,  0.3810,  0.3490,  0.3383,\n",
      "          -0.2508,  0.2642,  0.3380,  0.3392],\n",
      "         [-0.0051, -0.0850,  0.0874, -0.0497, -0.0295,  0.1699,  0.2016,\n",
      "          -0.1115,  0.1710,  0.1937,  0.1268],\n",
      "         [ 0.0375, -0.1665,  0.3721,  0.0548,  0.0723,  0.0288,  0.3870,\n",
      "          -0.1574,  0.4688, -0.1863, -0.0720],\n",
      "         [-0.0330, -0.0486,  0.2763,  0.0426, -0.0266,  0.0830,  0.2558,\n",
      "          -0.1190,  0.5357,  0.1165,  0.0284],\n",
      "         [-0.0088, -0.1743,  0.0230,  0.2382,  0.2206,  0.2547,  0.2797,\n",
      "          -0.1766,  0.4029,  0.1020,  0.2997],\n",
      "         [ 0.2475, -0.0939,  0.1291,  0.0626,  0.3547,  0.3009,  0.3377,\n",
      "          -0.2535,  0.1962,  0.1432,  0.2696],\n",
      "         [-0.1394, -0.0765,  0.0622,  0.1391,  0.1256,  0.2459,  0.2773,\n",
      "          -0.2716,  0.2699,  0.1618,  0.1189],\n",
      "         [-0.0226, -0.0199,  0.2029,  0.0515, -0.0290,  0.0214,  0.2169,\n",
      "          -0.1571,  0.5168,  0.1161, -0.0450],\n",
      "         [ 0.0440,  0.0015,  0.2842,  0.0423, -0.0011,  0.1356,  0.2798,\n",
      "          -0.1544,  0.4987,  0.1377,  0.0791],\n",
      "         [ 0.1489, -0.0319,  0.1245, -0.0724, -0.0261,  0.0050,  0.1133,\n",
      "          -0.0632,  0.4962,  0.0216, -0.1062],\n",
      "         [-0.1291, -0.1515,  0.1960,  0.0980,  0.0952, -0.0017,  0.2134,\n",
      "          -0.2098,  0.6598,  0.2173, -0.0501],\n",
      "         [-0.0914, -0.3134,  0.1314,  0.1103,  0.2923,  0.1538,  0.3009,\n",
      "          -0.2497,  0.5243,  0.2926,  0.0654]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net=Net(input_size, hidden_size, output_size)\n",
    "\n",
    "outputs=net(X)\n",
    "print(outputs.shape, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 11])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.view(-1, input_size).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13])\n",
      "torch.Size([13])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(Y.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 2.3557629585266113 prediction: [[8 4 6 8 8 8 4 6 8 8 8 8 8]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: rmorrrmorrrrr\n",
      "1 loss 2.1063084602355957 prediction: [[8 6 8 6 6 6 8 8 6 6 8 8 8]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: rorooorroorrr\n",
      "2 loss 1.7553343772888184 prediction: [[8 9 3 6 6 0 8 8 6 6 8 8 4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: rthoo rroorrm\n",
      "3 loss 1.3907759189605713 prediction: [[10  9  3  6  2  0  8  4  6  2  8  8  4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: ythog rmogrrm\n",
      "4 loss 1.005553960800171 prediction: [[10  9  3  6  5  0  8  8  6  2  8  1  4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: ython rrogram\n",
      "5 loss 0.7259743809700012 prediction: [[10  9  3  6  5  0  8  8  6  2  8  1  4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: ython rrogram\n",
      "6 loss 0.4837862253189087 prediction: [[10  9  3  6  5  0  7  8  6  2  8  1  4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: ython program\n",
      "7 loss 0.30340954661369324 prediction: [[10  9  3  6  5  0  7  8  6  2  8  1  4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: ython program\n",
      "8 loss 0.18715333938598633 prediction: [[10  9  3  6  5  0  7  8  6  2  8  1  4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: ython program\n",
      "9 loss 0.11370489001274109 prediction: [[10  9  3  6  5  0  7  8  6  2  8  1  4]] true Y [[10, 9, 3, 6, 5, 0, 7, 8, 6, 2, 8, 1, 4]] prediction_str: ython program\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs=net(X)\n",
    "    loss=criterion(outputs.view(-1, input_size), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    result=outputs.data.numpy().argmax(axis=2)\n",
    "    result_str=''.join([index_to_char[c] for c in np.squeeze(result)])\n",
    "    print(i, \"loss\", loss.item(), \"prediction:\", result, \"true Y\", y_data, \"prediction_str:\", result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
